{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementation and Explanation**"
      ],
      "metadata": {
        "id": "_dmn2U0sDS2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Matrix and Kernel"
      ],
      "metadata": {
        "id": "RMDPMs7GMlAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import KernelPCA, PCA\n",
        "from typing import Tuple, List\n",
        "\n",
        "def compute_correlation_matrix(data: np.ndarray, rowvar: bool = False) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the correlation matrix using PCA.\n",
        "\n",
        "    Args:\n",
        "    data (np.ndarray): Input data where columns represent variables and rows represent samples.\n",
        "    rowvar (bool): Whether the data is row-variate (columns are variables) or column-variate (rows are variables). Default is False.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: The correlation matrix.\n",
        "    \"\"\"\n",
        "    correlation_matrix = np.corrcoef(data, rowvar=rowvar)\n",
        "    return correlation_matrix\n",
        "\n",
        "\n",
        "def compute_kernel_matrix(data: np.ndarray, kernel: str = 'rbf', gamma: float = 0.1) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the kernel matrix using KernelPCA.\n",
        "\n",
        "    Args:\n",
        "    data (np.ndarray): Input data where columns represent variables and rows represent samples.\n",
        "    kernel (str): Type of kernel to use. Default is 'rbf'.\n",
        "    gamma (float): Kernel coefficient for rbf, poly, and sigmoid kernels. Default is 0.1.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: The kernel matrix.\n",
        "    \"\"\"\n",
        "    kpca = KernelPCA(n_components=data.shape[1], kernel=kernel, gamma=gamma)\n",
        "    kernel_matrix = kpca.fit_transform(data.T)\n",
        "    return kernel_matrix\n",
        "\n",
        "def compute_eigenvalues_and_eigenvectors(matrix: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Computes the eigenvalues and eigenvectors of a given matrix.\n",
        "\n",
        "    Args:\n",
        "    matrix (np.ndarray): Input matrix.\n",
        "\n",
        "    Returns:\n",
        "    Tuple[np.ndarray, np.ndarray]: Eigenvalues and eigenvectors.\n",
        "    \"\"\"\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(matrix)\n",
        "    return eigenvalues, eigenvectors\n",
        "\n",
        "def eigenvalue_analysis(eigenvalues: np.ndarray, threshold: float = 0.95) -> List[int]:\n",
        "    \"\"\"\n",
        "    Perform eigenvalue analysis to identify the set of conflicting objectives along significant principal components.\n",
        "\n",
        "    Args:\n",
        "    eigenvalues (np.ndarray): Eigenvalues of the matrix.\n",
        "    threshold (float): Variance threshold to determine significant components. Default is 0.95.\n",
        "\n",
        "    Returns:\n",
        "    List[int]: List of indices of significant principal components.\n",
        "    \"\"\"\n",
        "    total_variance = np.sum(eigenvalues)\n",
        "    explained_variance_ratio = eigenvalues / total_variance\n",
        "    cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
        "\n",
        "    significant_components = np.where(cumulative_variance_ratio >= threshold)[0] + 1\n",
        "    return significant_components\n",
        "\n"
      ],
      "metadata": {
        "id": "KCgYnbJTC94n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selection of Objectives"
      ],
      "metadata": {
        "id": "R_eNmAi0Pb06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "\n",
        "# Continue with the functions we defined earlier\n",
        "\n",
        "def reduced_correlation_matrix_analysis(corr_matrix: np.ndarray, eigenvalues: np.ndarray, eigenvectors: np.ndarray, T_cor: float = 0.5) -> List[List[int]]:\n",
        "    \"\"\"\n",
        "    Perform Reduced Correlation Matrix (RCM) Analysis to identify identically correlated subsets.\n",
        "\n",
        "    Args:\n",
        "    corr_matrix (np.ndarray): Correlation matrix.\n",
        "    eigenvalues (np.ndarray): Eigenvalues of the matrix.\n",
        "    eigenvectors (np.ndarray): Eigenvectors of the matrix.\n",
        "    T_cor (float): Correlation threshold. Default is 0.5.\n",
        "\n",
        "    Returns:\n",
        "    List[List[int]]: List of lists where each sublist represents an identically correlated subset.\n",
        "    \"\"\"\n",
        "    num_objs = corr_matrix.shape[0]\n",
        "    identically_correlated_subsets = []\n",
        "\n",
        "    for i in range(num_objs):\n",
        "        subset = [i]\n",
        "        for j in range(num_objs):\n",
        "            if i != j and np.abs(corr_matrix[i, j]) >= T_cor:\n",
        "                subset.append(j)\n",
        "        if subset not in identically_correlated_subsets:\n",
        "            identically_correlated_subsets.append(subset)\n",
        "\n",
        "    return identically_correlated_subsets\n",
        "\n",
        "def selection_scheme(identically_correlated_subsets: List[List[int]], eigenvectors: np.ndarray) -> List[int]:\n",
        "    \"\"\"\n",
        "    Apply the selection scheme to identify the most significant objective in each identically correlated subset.\n",
        "\n",
        "    Args:\n",
        "    identically_correlated_subsets (List[List[int]]): List of identically correlated subsets.\n",
        "    eigenvectors (np.ndarray): Eigenvectors of the matrix.\n",
        "\n",
        "    Returns:\n",
        "    List[int]: List of indices of the most significant objectives.\n",
        "    \"\"\"\n",
        "    selected_objectives = []\n",
        "\n",
        "    for subset in identically_correlated_subsets:\n",
        "        subset_eigenvectors = eigenvectors[:, subset]\n",
        "        subset_variance = np.sum(np.var(subset_eigenvectors, axis=1))\n",
        "        most_significant_obj_index = subset[np.argmax(subset_variance)]\n",
        "        selected_objectives.append(most_significant_obj_index)\n",
        "\n",
        "    return selected_objectives\n",
        "\n",
        "def compute_error(data: np.ndarray, selected_objectives: List[int]) -> List[float]:\n",
        "    \"\"\"\n",
        "    Compute the error associated with each objective.\n",
        "\n",
        "    Args:\n",
        "    data (np.ndarray): Input data where columns represent variables and rows represent samples.\n",
        "    selected_objectives (List[int]): List of indices of the selected objectives.\n",
        "\n",
        "    Returns:\n",
        "    List[float]: List of errors associated with each objective.\n",
        "    \"\"\"\n",
        "    errors = []\n",
        "\n",
        "    for obj_index in selected_objectives:\n",
        "        remaining_indices = [i for i in range(data.shape[1]) if i != obj_index]\n",
        "        reduced_data = data[:, remaining_indices]\n",
        "        reduced_correlation_matrix = compute_correlation_matrix(reduced_data)\n",
        "        error = np.trace(reduced_correlation_matrix)\n",
        "        errors.append(error)\n",
        "\n",
        "    return errors\n",
        "\n",
        "# Implement the remaining steps (8 to 12) following your descriptions.\n",
        "\n",
        "def main(data):\n",
        "    #data = np.random.rand(5, 50)  # Replace with your actual data\n",
        "\n",
        "    # Step 6: Reduced Correlation Matrix Analysis\n",
        "    corr_matrix = compute_correlation_matrix(data)\n",
        "    eigenvalues, eigenvectors = compute_eigenvalues_and_eigenvectors(corr_matrix)\n",
        "    T_correlation = 0.5  # Adjust this threshold as needed\n",
        "    identically_correlated_subsets = reduced_correlation_matrix_analysis(corr_matrix, eigenvalues, eigenvectors, T_correlation)\n",
        "    print(\"\\nIdentically Correlated Subsets:\")\n",
        "    print(identically_correlated_subsets)\n",
        "\n",
        "    # Step 7: Selection Scheme\n",
        "    selected_objectives = selection_scheme(identically_correlated_subsets, eigenvectors)\n",
        "    print(\"\\nSelected Objectives:\")\n",
        "    print(selected_objectives)\n",
        "\n",
        "    # Step 8: Compute Error\n",
        "    errors = compute_error(data, selected_objectives)\n",
        "    print(\"\\nErrors Associated with Selected Objectives:\")\n",
        "    print(errors)\n",
        "\n",
        "    # Continue with the implementation of the remaining steps (9 to 12) as described in your document.\n"
      ],
      "metadata": {
        "id": "a7qfcG7RPfpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problems"
      ],
      "metadata": {
        "id": "izZi_KlHVFyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/msu-coinlab/pymop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e61oL8k3VEO6",
        "outputId": "04edd51b-770a-43b1-ed00-dc6efdfe1ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/msu-coinlab/pymop\n",
            "  Cloning https://github.com/msu-coinlab/pymop to /tmp/pip-req-build-byayq8zz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/msu-coinlab/pymop /tmp/pip-req-build-byayq8zz\n",
            "  Resolved https://github.com/msu-coinlab/pymop to commit 7b7e789e640126c6d254e86ede5d7f4baad7eaa5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pymop==0.2.4) (1.23.5)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pymop==0.2.4) (1.6.2)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd->pymop==0.2.4) (0.18.3)\n",
            "Building wheels for collected packages: pymop\n",
            "  Building wheel for pymop (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pymop: filename=pymop-0.2.4-py3-none-any.whl size=43638 sha256=20ac4d4db47fd6f551852833a87c7c770397891be6e31d35e2783a421b0387dc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-usm41t_1/wheels/bd/df/1c/0dd14bf65c12caaa4c11bb5ad03d03b802ab48ad29e8eeef72\n",
            "Successfully built pymop\n",
            "Installing collected packages: pymop\n",
            "Successfully installed pymop-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymop\n",
        "\n"
      ],
      "metadata": {
        "id": "R6gSPY2lVil6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DLTZ2"
      ],
      "metadata": {
        "id": "ztW1cphkVKUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import factorial\n",
        "\n",
        "PROBLEM = \"dtlz2\"\n",
        "NOBJ = 3\n",
        "K = 10\n",
        "NDIM = NOBJ + K - 1\n",
        "P = 12\n",
        "H = factorial(NOBJ + P - 1) / (factorial(P) * factorial(NOBJ - 1))\n",
        "BOUND_LOW, BOUND_UP = 0.0, 1.0\n",
        "#problem = pymop.factory.get_problem(PROBLEM, n_var=NDIM, n_obj=NOBJ)\n",
        "problem = pymopfactory.get_problem(PROBLEM, n_var=NDIM, n_obj=NOBJ)"
      ],
      "metadata": {
        "id": "J22pZ-EAVYCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ref_dirs = pymop.factory.get_uniform_weights(100, 3)\n",
        "dltz2=problem.pareto_front(ref_dirs)"
      ],
      "metadata": {
        "id": "dJ7_woZdVlnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(dltz2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFRG-bCPV8gC",
        "outputId": "7a35e2a5-02a0-48bb-bee7-e9faada57829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Identically Correlated Subsets:\n",
            "[[0], [1], [2]]\n",
            "\n",
            "Selected Objectives:\n",
            "[0, 1, 2]\n",
            "\n",
            "Errors Associated with Selected Objectives:\n",
            "[2.0, 2.0, 2.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DLTZ5"
      ],
      "metadata": {
        "id": "j9gcMp1SXnoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem definition\n",
        "PROBLEM = \"dtlz5\"\n",
        "NOBJ = 10\n",
        "K = 1 #nvars - nobj + 1\n",
        "NDIM = NOBJ + K - 1\n",
        "\n",
        "# numb. of reference points - directions on the objective space - a parameter for NSGA-III\n",
        "#P = 5 - 4\n",
        "#P = 7 - 4\n",
        "#P = 14 - 4\n",
        "\n",
        "#H = factorial(NOBJ + P - 1) / (factorial(P) * factorial(NOBJ - 1))\n",
        "BOUND_LOW, BOUND_UP = 0.0, 1.0\n",
        "problem = pymop.factory.get_problem(PROBLEM, n_var=NDIM, n_obj=NOBJ)"
      ],
      "metadata": {
        "id": "0ig8cai_XstX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ref_dirs = pymop.factory.get_uniform_weights(100, 3)\n",
        "dltz5=problem.pareto_front()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "G5dFhvfvXw3u",
        "outputId": "51702c74-36b0-4f93-bd18-d3c749769677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-deb6abcae3d6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ref_dirs = pymop.factory.get_uniform_weights(100, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdltz5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpareto_front\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymop/problem.py\u001b[0m in \u001b[0;36mpareto_front\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pareto_front\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pareto_front\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_pareto_front\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pareto_front\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pymop/problems/dtlz.py\u001b[0m in \u001b[0;36m_calc_pareto_front\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_calc_pareto_front\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not implemented yet.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Not implemented yet."
          ]
        }
      ]
    }
  ]
}